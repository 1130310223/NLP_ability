autoner：如何缓解ner远程监督中的噪声标签

今天分享[autoner]("https://arxiv.org/abs/1809.03599", Learning Named Entity Tagger using Domain-Specific Dictionary)，只是使用词典标注就可以做到和监督学习ner效果可比：

对于NER中的标注数据，我们可以使用人工进行去打标，相对来说准确度高，但是成本可能很大。

另一个思路就是积累对应的领域词典，然后使用词典的方式对大量的无标签数据进行远程监督的打标。

这种方式速度快，但是生成的噪声标签是一个问题。

什么是噪声标签呢？比如说，我有一个关于地名的领域词典，里面有一个实体的名称是【南京】；

现在我的无标注数据中，有这样一句话，【我去南京长江大桥去玩了】；

在这句话中，【南京长江大桥】这是实体才是我们想要的，但是通过词典，很可能只是标注了【南京】这两个字。

这就是噪声标签。

ner中还存在一个问题就是嵌套实体的东西，还是上面那个例子，

还存在一个问题，句子中，没有被词典打中的东西，都会被认为是无标签的。但是这样也是一个问题。假设词典中的内容是【长江大桥】，在对【我去南京长江大桥去玩了】词典打标的时候，打上了【长江大桥】，除此之外的，我们都不认为是实体。但是由于词典规模是有限的，【南京】这个很明显是一个高质量的短语，虽然它不存在，但是由于规模有限，他很有可能是词典中的某一个类别。

说到这里，我自己有一个思考。是实体，但是不存在于词典之中，这也分情况。

比如说，你做地名的识别，【南京】这个不在你的词典中，你就会漏标，着很严重。但是【郭敬明】这种人名，不在你的词典中，就没啥问题。

所以在做短语挖掘的时候，感觉是什么类型都会挖出来。既有【南京】这种地名，又有【郭敬明】这种人名，有一种全部覆盖的感觉。

还有一种情况是实体可以被打上多个标签，比如科技词典中的【苹果】和水果领域的【苹果】，对于这种情况，有两种解决办法。

这个其实属于实体歧义的问题，但是在词典打标的时候，你没有办法避免，而且在训练的时候，最好两个都训练出来

这个论文主要是有两个贡献，一个是使用fuzzy CRF在传统标注框架下，处理多标签的tokens，一个是提出了autoner，使用新的标框架。



首先，在传统的标注框架下（BIO或者BIOES标注体系），把LSTm-CRF中的CRF层替换为了FUzzy CRF，以此来应对同一个实体对应多个标签问题。

进一步的，作者提出了另一种解决办法，本质其实是换了一个标注体系，不再是关注每个token的类别，而是判断两个相邻的token是不是在同一个实体中。



简单总结就是缓解两个问题，一个是unknow实体怎么处理，一个是对应多类别实体怎么处理（也就是嵌套实体）

首先，论文的目标是为了能够仅仅使用词典就可以做到命名体识别。

本文中词典包含两个部分：首先是实体的规范化名称以及它的对应同义词表。比如一个地名的规范化名称是【百度大厦】，同义词表示比如说是【后厂村路某某号某某院】。其次需要包含实体类别。比如【百度大厦】对应的就是地名这个实体类别。因为实体类别都是有限的，所以使用方法扩展高质量的短语作为unkown的实体类别。

给定我们的一个原始语料和词典，我们通过字符匹配首先产生实体标签，包括unkown标签；

完成之后，对于每个token会有三种情况，1这个token属于某一个已知实体或者某几个已知实体；2这个token属于unkown实体类别，3被标记为无实体类别。



# 1. Fuzzy-LSTM-CRF 

处理unkown实体和多标签实体。

1. Modified IOBES

正常的 IOBES 就是按照实体类型和实体位置，找到对应标签就可以。这里的话，首先如果对应多标签，对应的实体类型和位置全部标上。其次，对于unkown实体，BIOES五个类型（对应的不同类别就更多了）全部标上，也就是unkown对应的是全部的标签类型。对于没有匹配上的，使用o。

2. Fuzzy-LSTM-CRF

其实很好理解，传统的CRF最大化唯一一条有效的标注序列。在这列，我们最大化所有有可能的标注序列。

公式如下：

![Fuzzy-LSTM-CRF优化公式](https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-07-53045.jpg)

看架构图：

![Fuzzy-LSTM-CRF](https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-07-053047.jpg)

# 2. AutoNER

Tie or Break 标注框架：

这个标注框架更加关注的是当前token和上一个token是否在同一个实体里面，如果在同一个实体里面，那么就标注为Tie；如果当前单词和上一个单词至少有一个在unkonw类型的高质量短语，那么当前token标注为unkonw，其他情况标注为Break

优化过程：把实体识别和实体类型识别分离开，分别优化。

对于实体识别，对于当前单词的输出，对Tie和Break做二分类损失，如果当前token类别是unkown类别，直接跳过，不计算损失。

概率公式如下：

![tie_break_loss](https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-07-053043.jpg)

![tie_break_loss](https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-07-053045.jpg)

第二步预测实体类型，包含None实体类型

unkonw这种，知道是个实体，在高质量短语词典中，但是不知道短语类型，所在这里我们会标注为None实体类型。

其他的不在词典中的，当然也就会被标注为None实体类型。

为了应对多标签，也就是同一个实体对应不同的类别，这里修改了最后的CE损失函数：

![CE_总](https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-07-053046.jpg)

![CE_Soft](https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-07-053044.jpg)

这里如果我没看错的话，使用的是软标签的进行的CE的计算，并没有使用硬标签（如果我理解问题，大家联系我修改一下这里）。

$L_{i}$对应的是在远程监督中，当前实体真实类型标签集合。从公式我们可以知道，在不属于这个集合的标签概率我们并没有计算在内。

# 总结

两种方法处理无标签的高质量短语和同一个实体对应多个标签的问题。

首先是Fuzzy-LSTM-CRF：对于无标签高质量短语，全部标签都标注，对于多标签，打标对应类别，在训练的时候，优化全部可能的路径。

其次是autoner，将实体的识别和实体类别的识别分离，使用Tie/Break对token进行标记。对于实体的识别，需要跳过unkown类型，做二分类计算损失。对于实体类型的识别，尤其是多标签实体，使用软标签分布进行交叉熵的度量。

Autoner不包含CRF，所以速度会快一点。